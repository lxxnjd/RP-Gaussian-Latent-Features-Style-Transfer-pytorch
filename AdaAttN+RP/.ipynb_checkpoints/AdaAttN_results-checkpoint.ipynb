{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ae2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# %load user_specify_demo.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "#只改动content_path,style_path即可，结果在results\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_img(path, h, w):\n",
    "    img = Image.open(path).convert('RGB').resize((w, h))\n",
    "    img = (torch.from_numpy(np.array(img).transpose((2, 0, 1))).float() / 255.).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def save_img(img, path):\n",
    "    img = (img[0].data.cpu().numpy().transpose((1, 2, 0)).clip(0, 1) * 255 + 0.5).astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    img.save(path)\n",
    "\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def mean_variance_norm(feat):\n",
    "    size = feat.size()\n",
    "    mean, std = calc_mean_std(feat)\n",
    "    normalized_feat = (feat - mean.expand(size)) / std.expand(size)\n",
    "    return normalized_feat\n",
    "\n",
    "\n",
    "def get_key(feats, last_layer_idx):\n",
    "    results = []\n",
    "    _, _, h, w = feats[last_layer_idx].shape\n",
    "    for i in range(last_layer_idx):\n",
    "        results.append(mean_variance_norm(nn.functional.interpolate(feats[i], (h, w))))\n",
    "    results.append(mean_variance_norm(feats[last_layer_idx]))\n",
    "    return torch.cat(results, dim=1)\n",
    "\n",
    "\n",
    "class AttnAdaIN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, max_sample=256 * 256, key_planes=None):\n",
    "        super(AttnAdaIN, self).__init__()\n",
    "        if key_planes is None:\n",
    "            key_planes = in_planes\n",
    "        self.f = nn.Conv2d(key_planes, key_planes, (1, 1))\n",
    "        self.g = nn.Conv2d(key_planes, key_planes, (1, 1))\n",
    "        self.h = nn.Conv2d(in_planes, in_planes, (1, 1))\n",
    "        self.sm = nn.Softmax(dim=-1)\n",
    "        self.max_sample = max_sample\n",
    "\n",
    "    def forward(self, content, style, content_key, style_key, seed=None, content_mask=None, style_mask=None):\n",
    "        F = self.f(content_key)\n",
    "        G = self.g(style_key)\n",
    "        H = self.h(style)\n",
    "        b, _, h_g, w_g = G.size()\n",
    "        G = G.view(b, -1, w_g * h_g).contiguous()\n",
    "        if style_mask is not None:\n",
    "            style_mask = nn.functional.interpolate(\n",
    "                style_mask, size=(h_g, w_g), mode='nearest').view(b, 1, w_g * h_g).contiguous()\n",
    "        else:\n",
    "            style_mask = torch.ones(b, 1, w_g * h_g, device=style.device)\n",
    "        if w_g * h_g > self.max_sample:\n",
    "            if seed is not None:\n",
    "                torch.manual_seed(seed)\n",
    "            index = torch.randperm(w_g * h_g).to(content.device)[:self.max_sample]\n",
    "            G = G[:, :, index]\n",
    "            style_mask = style_mask[:, :, index]\n",
    "            style_flat = H.view(b, -1, w_g * h_g)[:, :, index].transpose(1, 2).contiguous()\n",
    "        else:\n",
    "            style_flat = H.view(b, -1, w_g * h_g).transpose(1, 2).contiguous()\n",
    "        b, _, h, w = F.size()\n",
    "        F = F.view(b, -1, w * h).permute(0, 2, 1)\n",
    "        if content_mask is not None:\n",
    "            content_mask = nn.functional.interpolate(\n",
    "                content_mask, size=(h, w), mode='nearest').view(b, 1, w * h).permute(0, 2, 1).contiguous()\n",
    "        else:\n",
    "            content_mask = torch.ones(b, w * h, 1, device=content.device)\n",
    "        S = torch.bmm(F, G)\n",
    "        style_mask = 1. - style_mask\n",
    "        attn_mask = torch.bmm(content_mask, style_mask)\n",
    "        S = S.masked_fill(attn_mask.bool(), -1e15)\n",
    "        # S: b, n_c, n_s\n",
    "        S = self.sm(S)\n",
    "        # mean: b, n_c, c\n",
    "        mean = torch.bmm(S, style_flat)\n",
    "        # std: b, n_c, c\n",
    "        std = torch.sqrt(torch.relu(torch.bmm(S, style_flat ** 2) - mean ** 2))\n",
    "        # mean, std: b, c, h, w\n",
    "        mean = mean.view(b, h, w, -1).permute(0, 3, 1, 2).contiguous()\n",
    "        std = std.view(b, h, w, -1).permute(0, 3, 1, 2).contiguous()\n",
    "        return std * mean_variance_norm(content) + mean\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, key_planes=None):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.attn_adain_4_1 = AttnAdaIN(in_planes=in_planes, key_planes=key_planes)\n",
    "        self.attn_adain_5_1 = AttnAdaIN(in_planes=in_planes, key_planes=key_planes + 512)\n",
    "        self.upsample5_1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.merge_conv_pad = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.merge_conv = nn.Conv2d(in_planes, in_planes, (3, 3))\n",
    "\n",
    "    def forward(self, content4_1, style4_1, content5_1, style5_1, content4_1_key, style4_1_key,\n",
    "                content5_1_key, style5_1_key, seed=None, content_mask=None, style_mask=None):\n",
    "        return self.merge_conv(self.merge_conv_pad(\n",
    "            self.attn_adain_4_1(\n",
    "                content4_1, style4_1, content4_1_key, style4_1_key, seed, content_mask, style_mask) +\n",
    "            self.upsample5_1(self.attn_adain_5_1(\n",
    "                content5_1, style5_1, content5_1_key, style5_1_key, seed, content_mask, style_mask))))\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layer_1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(512, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "        self.decoder_layer_2 = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256 + 256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 256, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(256, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 128, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(128, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(64, 3, (3, 3))\n",
    "        )\n",
    "\n",
    "    def forward(self, cs, c_adain_3_feat):\n",
    "        cs = self.decoder_layer_1(cs)\n",
    "        cs = self.decoder_layer_2(torch.cat((cs, c_adain_3_feat), dim=1))\n",
    "        return cs\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "# transformer_path = 'models/attn_adain_without_ss_idt/latest_net_transformer.pth'\n",
    "# decoder_path = 'models/attn_adain_without_ss_idt/latest_net_decoder.pth'\n",
    "# attn_adain_3_path = 'models/attn_adain_without_ss_idt/latest_net_attn_adain_3.pth'\n",
    "transformer_path = './checkpoints/AdaAttN/latest_net_transformer.pth'\n",
    "decoder_path = './checkpoints/AdaAttN/latest_net_decoder.pth'\n",
    "attn_adain_3_path = './checkpoints/AdaAttN/latest_net_adaattn_3.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_encoder = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1, 1)),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU()  # relu5-4\n",
    ")\n",
    "image_encoder.load_state_dict(torch.load('./checkpoints/vgg_normalised.pth'))\n",
    "enc_layers = list(image_encoder.children())\n",
    "enc_1 = nn.Sequential(*enc_layers[:4]).to(device)\n",
    "enc_2 = nn.Sequential(*enc_layers[4:11]).to(device)\n",
    "enc_3 = nn.Sequential(*enc_layers[11:18]).to(device)\n",
    "enc_4 = nn.Sequential(*enc_layers[18:31]).to(device)\n",
    "enc_5 = nn.Sequential(*enc_layers[31:44]).to(device)\n",
    "image_encoder_layers = [enc_1, enc_2, enc_3, enc_4, enc_5]\n",
    "for layer in image_encoder_layers:\n",
    "    layer.eval()\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "transformer = Transformer(in_planes=512, key_planes=512 + 256 + 128 + 64).to(device)\n",
    "decoder = Decoder().to(device)\n",
    "attn_adain_3 = AttnAdaIN(in_planes=256, key_planes=256 + 128 + 64, max_sample=256 * 256).to(device)\n",
    "transformer.load_state_dict(torch.load(transformer_path))\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "attn_adain_3.load_state_dict(torch.load(attn_adain_3_path))\n",
    "transformer.eval()\n",
    "decoder.eval()\n",
    "attn_adain_3.eval()\n",
    "for param in transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in attn_adain_3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "def encode_with_intermediate(img):\n",
    "    results = [img]\n",
    "    for i in range(len(image_encoder_layers)):\n",
    "        func = image_encoder_layers[i]\n",
    "        results.append(func(results[-1]))\n",
    "    return results[1:]\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "#此处修改路径为文件夹路径，需要代码底部的for循环\n",
    "# content_path = './datasets/contents/bair.jpg'\n",
    "# style_path = './datasets/styles/wave.jpg'\n",
    "# content_name = os.path.basename(content_path)\n",
    "# style_name = os.path.basename(style_path)\n",
    "# tgt_path = './results/'+content_name[:content_name.rfind('.')] + '_' + style_name[:style_name.rfind('.')] + '.jpg'\n",
    "# In[4]:\n",
    "\n",
    "# btn_down = False\n",
    "# point_a = (0, 0)\n",
    "# x_max = 0\n",
    "# x_min = 1e10\n",
    "# y_max = 0\n",
    "# y_min = 1e10\n",
    "# content_im = cv2.imread(content_path)\n",
    "# content_im = cv2.resize(content_im, (512, 512))\n",
    "# content_result = content_im.copy()\n",
    "# h, w = content_result.shape[:2]\n",
    "# content_canvas = np.zeros([h, w, 3], np.uint8)\n",
    "# content_mask = np.zeros([h, w], np.uint8)\n",
    "\n",
    "\n",
    "def mouse_content_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        global content_mask, content_result\n",
    "        content_result = content_im.copy()\n",
    "        h, w = content_result.shape[:2]\n",
    "        content_mask = np.zeros([h + 2, w + 2], np.uint8)\n",
    "        cv2.floodFill(content_result, content_mask, (x, y), (255, 255, 255),\n",
    "                      (50, 50, 50), (50, 50, 50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "        content_mask = content_mask[1:-1, 1:-1]\n",
    "        cv2.imshow('Content Image', content_result)\n",
    "\n",
    "\n",
    "def mouse_content_paint(event, x, y, flags, param):\n",
    "    global btn_down, point_a, x_max, x_min, y_max, y_min\n",
    "    if event == cv2.EVENT_LBUTTONUP and btn_down:\n",
    "        btn_down = False\n",
    "        cv2.line(content_result, point_a, (x, y), (255, 255, 255))\n",
    "        cv2.line(content_canvas, point_a, (x, y), (255, 255, 255))\n",
    "        point_a = (x, y)\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        cv2.imshow('Content Image', content_result)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and btn_down:\n",
    "        cv2.line(content_result, point_a, (x, y), (255, 255, 255))\n",
    "        cv2.line(content_canvas, point_a, (x, y), (255, 255, 255))\n",
    "        point_a = (x, y)\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        cv2.imshow('Content Image', content_result)\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        btn_down = True\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        point_a = (x, y)\n",
    "\n",
    "\n",
    "# print('Please choose an interactive mode for content image:')\n",
    "# print('\\t1: Click Mode')\n",
    "# print('\\t2: Paint Mode')\n",
    "# print('\\tOther: No Interaction')\n",
    "# option = input()\n",
    "# if option == '1':\n",
    "#     cv2.namedWindow('Content Image', cv2.WINDOW_AUTOSIZE)\n",
    "#     cv2.imshow('Content Image', content_im)\n",
    "#     cv2.setMouseCallback('Content Image', mouse_content_click)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(content_name[:content_name.rfind('.')] + '_interactive.jpg', content_result)\n",
    "# elif option == '2':\n",
    "#     cv2.namedWindow('Content Image', cv2.WINDOW_AUTOSIZE)\n",
    "#     cv2.imshow('Content Image', content_im)\n",
    "#     cv2.setMouseCallback('Content Image', mouse_content_paint)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     content_mask = np.zeros([h + 2, w + 2], np.uint8)\n",
    "#     cv2.floodFill(content_canvas, content_mask, (int((x_max + x_min) / 2), int((y_max + y_min) / 2)), (255, 255, 255),\n",
    "#                   (50, 50, 50), (50, 50, 50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "#     content_mask = content_mask[1:-1, 1:-1]\n",
    "#     cv2.imwrite(content_name[:content_name.rfind('.')] + '_interactive.jpg', content_result)\n",
    "\n",
    "# In[5]:\n",
    "# btn_down = False\n",
    "# point_a = (0, 0)\n",
    "# x_max = 0\n",
    "# x_min = 1e10\n",
    "# y_max = 0\n",
    "# y_min = 1e10\n",
    "# style_im = cv2.imread(style_path)\n",
    "# style_im = cv2.resize(style_im, (512, 512))\n",
    "# style_result = style_im.copy()\n",
    "# h, w = style_result.shape[:2]\n",
    "# style_canvas = np.zeros([h, w, 3], np.uint8)\n",
    "# style_mask = np.zeros([h, w], np.uint8)\n",
    "\n",
    "\n",
    "def mouse_style_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        global style_mask, style_result\n",
    "        style_result = style_im.copy()\n",
    "        h, w = style_result.shape[:2]\n",
    "        style_mask = np.zeros([h + 2, w + 2], np.uint8)\n",
    "        cv2.floodFill(style_result, style_mask, (x, y), (255, 255, 255),\n",
    "                      (50, 50, 50), (50, 50, 50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "        style_mask = style_mask[1:-1, 1:-1]\n",
    "        cv2.imshow('Style Image', style_result)\n",
    "\n",
    "\n",
    "def mouse_style_paint(event, x, y, flags, param):\n",
    "    global btn_down, point_a, x_max, x_min, y_max, y_min\n",
    "    if event == cv2.EVENT_LBUTTONUP and btn_down:\n",
    "        btn_down = False\n",
    "        cv2.line(style_result, point_a, (x, y), (255, 255, 255))\n",
    "        cv2.line(style_canvas, point_a, (x, y), (255, 255, 255))\n",
    "        point_a = (x, y)\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        cv2.imshow('Style Image', style_result)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and btn_down:\n",
    "        cv2.line(style_result, point_a, (x, y), (255, 255, 255))\n",
    "        cv2.line(style_canvas, point_a, (x, y), (255, 255, 255))\n",
    "        point_a = (x, y)\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        cv2.imshow('Style Image', style_result)\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        btn_down = True\n",
    "        if x > x_max:\n",
    "            x_max = x\n",
    "        if x < x_min:\n",
    "            x_min = x\n",
    "        if y > y_max:\n",
    "            y_max = y\n",
    "        if y < y_min:\n",
    "            y_min = y\n",
    "        point_a = (x, y)\n",
    "\n",
    "\n",
    "# print('Please choose an interactive mode for style image:')\n",
    "# print('\\t1: Click Mode')\n",
    "# print('\\t2: Paint Mode')\n",
    "# print('\\tOther: No Interaction')\n",
    "# option = input()\n",
    "# if option == '1':\n",
    "#     cv2.namedWindow('Style Image', cv2.WINDOW_AUTOSIZE)\n",
    "#     cv2.imshow('Style Image', style_im)\n",
    "#     cv2.setMouseCallback('Style Image', mouse_style_click)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(style_name[:style_name.rfind('.')] + '_interactive.jpg', style_result)\n",
    "# elif option == '2':\n",
    "#     cv2.namedWindow('Style Image', cv2.WINDOW_AUTOSIZE)\n",
    "#     cv2.imshow('Style Image', style_im)\n",
    "#     cv2.setMouseCallback('Style Image', mouse_style_paint)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     style_mask = np.zeros([h + 2, w + 2], np.uint8)\n",
    "#     cv2.floodFill(style_canvas, style_mask, (int((x_max + x_min) / 2), int((y_max + y_min) / 2)), (255, 255, 255),\n",
    "#                   (50, 50, 50), (50, 50, 50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "#     style_mask = style_mask[1:-1, 1:-1]\n",
    "#     cv2.imwrite(style_name[:style_name.rfind('.')] + '_interactive.jpg', style_result)\n",
    "\n",
    "# In[6]:\n",
    "root = \"D:/program files/2_cs_style_transfer/8_others/AdaAttN-add-license-1/datasets/out/\"\n",
    "content_dir = \"D:/program files/2_cs_style_transfer/8_others/AdaAttN-add-license-1/datasets/c/\"\n",
    "style_dir = \"D:/program files/2_cs_style_transfer/8_others/AdaAttN-add-license-1/datasets/s/\"\n",
    "num_max = len(os.listdir(content_dir))\n",
    "for num in tqdm(range(1,num_max+1)):\n",
    "    style_path = style_dir+os.listdir(style_dir)[num-1]\n",
    "    content_path = content_dir+os.listdir(content_dir)[num-1]\n",
    "    content_name = os.path.basename(content_path)\n",
    "    style_name = os.path.basename(style_path)\n",
    "    tgt_path = root+content_name[:content_name.rfind('.')] + '_' + style_name[:style_name.rfind('.')] + '.jpg'\n",
    "    with torch.no_grad():\n",
    "        style = read_img(style_path, h=256, w=256).to(device)#源代码此处设置为h=512,w=512\n",
    "        content = read_img(content_path, h=256, w=256).to(device)#源代码此处设置为h=512,w=512\n",
    "#     style_mask = torch.from_numpy(style_mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "#     content_mask = torch.from_numpy(content_mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "        c_feats = encode_with_intermediate(content)\n",
    "        s_feats = encode_with_intermediate(style)\n",
    "        c_adain_feat_3 = attn_adain_3(c_feats[2], s_feats[2], get_key(c_feats, 2), get_key(s_feats, 2), None,\n",
    "                                  content_mask=None, style_mask=None)#此处修改content_mask,style_mask\n",
    "        cs = transformer(c_feats[3], s_feats[3], c_feats[4], s_feats[4], get_key(c_feats, 3), get_key(s_feats, 3),\n",
    "                     get_key(c_feats, 4), get_key(s_feats, 4), None, content_mask=None, style_mask=None)#此处修改content_mask,style_mask\n",
    "        cs = decoder(cs, c_adain_feat_3)\n",
    "        save_img(cs, tgt_path)\n",
    "\n",
    "        \n",
    "        \n",
    "# #内容泄露迭代20次\n",
    "# # In[6]:/AdaAttN-add-license\"\n",
    "# root = \"F:/gdc/Neural_style_transfrom/AdaAttN-add-license-1/datasets/lhl/\"\n",
    "# content_dir = \"F:/gdc/Neural_style_transfrom/AdaAttN-add-license-1/datasets/contents/\"\n",
    "# style_dir = \"F:/gdc/Neural_style_transfrom/AdaAttN-add-license-1/datasets/style/\"\n",
    "# num_max = len(os.listdir(content_dir))\n",
    "# for epoch in range(1,20):\n",
    "#     for num in tqdm(range(1,num_max+1)):\n",
    "#         style_path = style_dir+os.listdir(style_dir)[num-1]\n",
    "#         content_path = content_dir+os.listdir(content_dir)[num-1]\n",
    "#         content_name = os.path.basename(content_path)\n",
    "#         style_name = os.path.basename(style_path)\n",
    "#         tgt_path = root+ '170508_c.jpg'\n",
    "#         with torch.no_grad():\n",
    "#             style = read_img(style_path, h=256, w=256).to(device)#源代码此处设置为h=512,w=512\n",
    "#             content = read_img(content_path, h=256, w=256).to(device)#源代码此处设置为h=512,w=512\n",
    "# #     style_mask = torch.from_numpy(style_mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "# #     content_mask = torch.from_numpy(content_mask).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "#             c_feats = encode_with_intermediate(content)\n",
    "#             s_feats = encode_with_intermediate(style)\n",
    "#             c_adain_feat_3 = attn_adain_3(c_feats[2], s_feats[2], get_key(c_feats, 2), get_key(s_feats, 2), None,\n",
    "#                                   content_mask=None, style_mask=None)#此处修改content_mask,style_mask\n",
    "#             cs = transformer(c_feats[3], s_feats[3], c_feats[4], s_feats[4], get_key(c_feats, 3), get_key(s_feats, 3),\n",
    "#                      get_key(c_feats, 4), get_key(s_feats, 4), None, content_mask=None, style_mask=None)#此处修改content_mask,style_mask\n",
    "#             cs = decoder(cs, c_adain_feat_3)\n",
    "#             save_img(cs, tgt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0f527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
